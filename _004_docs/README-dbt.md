# dbt Application

## ğŸ“‹ GENERAL 
This project used dbt to transform warehouse data into datamart. dbt handles the heavy lifting by creating modular, maintainable data models that power analytics.

## ğŸ¯ WHY USING DBT
1. Easily configure a materialization for each model
Handles boilerplate SQL
Turns SELECT queries into tables, views, or incremental models
2. Use a code compiler
Allows SQL files to include Jinja.
Enables repeated SQL to be shared through macros.
3. Determine the order of model execution
Provides the ref() function to reference other models instead of selecting from existing tables in the warehouse.
Determines the correct execution order.
4. Built-in documentation
Provides a mechanism to write, version-control, and share documentation for dbt models.
Supports plain text and markdown formatting.a
5. Models testing
Improves the integrity of the SQL models.
Provides built-in tests to validate the results generated by a model.
6. Package management
includes a built-in package manager.
Allows teams to use and publish both public and private repositories of dbt code.
7. Load seed files
Seed files are CSV files stored within the dbt project.
Commonly used for:
Mapping values
Static or infrequently changing enrichment data
8. Snapshot mutable data
Provides a mechanism to snapshot raw data for a point in time, through use of snapshots.
Implements type-2 Slowly Changing Dimensions over mutable source tables.

## ğŸ—ï¸ ARCHITECTURE AND CONFIGURATION
### Architecture
```
build_datamart/ 
â”‚
â”œâ”€â”€ profile.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ dbt_customer_behaviour_analytics_dmt/
         â”‚
         â”œâ”€â”€ dbt_project.yml
         â”œâ”€â”€ models/
         â”‚   â”œâ”€â”€ source/
         â”‚   â”‚   â””â”€â”€ gold_sources.yml
         â”‚   â”œâ”€â”€ dmt_search_event_base.sql
         â”‚   â”œâ”€â”€ dmt_search_event_category.sql
         â”‚   â”œâ”€â”€ dmt_search_event_plan.sql
         â”‚   â””â”€â”€ schema.yml
         â”‚
         â”œâ”€â”€ tests/
         â”œâ”€â”€ macros/
         â”œâ”€â”€ seeds/
         â”œâ”€â”€ snapshots/
         â””â”€â”€ analyses/
```
### Configuration
**Profile Configuration:**\
Stores warehouse connection settings:\
```python
dbt_customer_behaviour_analytics_dmt:
  outputs:
    dev:
      type: postgres
      host: localhost
      port: 5432
      user: admin
      password: "admin"
      dbname: postgres
      schema: datamart

    prod:
      type: postgres
      host: localhost
      port: 5432
      user: admin
      password: "admin"
      dbname: postgres
      schema: datamart

  target: dev
```

**Project configuration:**\
dbt is configured in the dbt_project.yml: \
``` python
name: 'dbt_customer_behaviour_analytics_dmt'
version: '1.0.0'
config-version: 2

profile: 'dbt_customer_behaviour_analytics_dmt'

model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

clean-targets:         # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"

models:
  dbt_customer_behaviour_analytics_dmt:
    +materialized: table
```

### Core Components
**Source of models:**\
Datamart is built from the gold layer of the data warehouse. In this project, gold layer is stored in postgreSQL database.\
```python
sources:
  - name: gold
    description: "Gold layer tables stored in PostgreSQL"
    database: postgres                     
    schema: dwh_user_search                 

    tables:
      - name: fact_customer_search
        description: "Search event fact table"

      - name: dim_date
        description:  "Date dimension table"

      - name: dim_user
        description: "User dimension table"

      - name: dim_platform
        description: "Platform dimension table"

      - name: dim_network
        description: "Network dimension table"

      - name: dim_subscription
        description: "Subscription dimension table"

      - name: bridge_user_plan
        description: "Bridge table mapping user to subscription"

      - name: dim_category
        description: "Category dimension table"
```

**Models:**\
Datamart database includes three tables supporting monthly analytics. These tables are built by SQL files, including:
- dmt_search_event_base.sql
- dmt_search_event_plan.sql
- dmt_search_event_category.sql
<img src="datamart.png">

All models are materialized as table since table is fast to query. Each table serves particularly analytical purposes. 

The dmt_search_event_base's grain is one search event per row and only events with action 'enter' are chosen to analyse. This datamart is the aggregation of 6/8 gold layer's tables and used for most charts of the monthly report. 
<img src="base.png">

The dmt_search_event_category's grain is one category of a search event per row. Since a search event may have more than one category and we want to analyse both main and sub category, we need to explode a search event into multiple rows. Some search events having main category defined as 'not matched' will be filtered out. This datamart serves analytical charts related to category such as 'Top category in a month'.
<img src="category.png">

The dmt_search_event_plan's grain is a plan type of a plan name per row. This table is used to visualize 'Top plan x plan type in a month' chart.
<img src="plan.png">

**Schema of models:**\
Schema is written in schema.yml. It defines:
- Modelâ€™s name
- Modelâ€™s description
- Column's name
- Column's description
- Data test to validate outputs. In this project, we used 3 main tests including not null, unique and accepted values.

## ğŸ’» TO USE DBT
1. Install required packages: 
dbt-core==1.7.13
dbt-postgres==1.7.13

2. Create profile.yml to store data warehouse connection settings.

3. Create dbt_project.yml to define:
- project name
- version
- profile name
- model paths and materialization settings

4. Define source and models

5. Use â€˜dbt runâ€™ to create datamart tables by SQL files in models folder.
<img src="dbt_run.png">

6. Use â€˜dbt testâ€™ to test the model outputs. All tests are defined in the schema.yml file.
<img src="dbt_test.png">

## âœ… Specific Benefits in the Projectf
1. Centralized Business Logic
All transformation logic is defined once in dbt models instead of being duplicated across BI tools. This ensures consistency across all dashboards.

2. Reusability
Core models can be reused across multiple charts without rewriting logic.

3. Maintainability
When business rules change, we update the dbt model once and all downstream reports automatically reflect the change.

4. Performance Optimization
We can pre-aggregate heavy transformations inside the data warehouse, reducing BI workload and improving dashboard performance.

5. Developer Experience:
Anyone comfortable with SQL can use dbt easily

## ğŸ“š References
- [What is dbt?](https://docs.getdbt.com/docs/introduction)
- [dbt materializations](https://docs.getdbt.com/docs/build/materializations)