# Apache Iceberg Application

## ğŸ“‹ General

This project uses **Apache Iceberg** as an open table format for the **Gold Layer** of the data warehouse. Iceberg provides efficient table management on S3, along with features such as **ACID transactions, time travel, schema evolution, and partition evolution**.

## ğŸ¯ Why using Apache Iceberg?

### 1. **ACID Transactions**
- Ensures **data consistency** during **concurrent read and write operations**
- Safely supports operations such as `MERGE INTO`, `UPDATE`, and `DELETE`
- Prevents issues related to **dirty reads** and **write conflicts**

### 2. **Time Travel & Snapshot Isolation**
- Enables querying data at **any point in time in the past**
- **Supports rollback** to a previous snapshot when needed
- Well-suited for **audit trails and compliance requirements**

### 3. **Schema Evolution**
- Allows **schema changes (adding, dropping, or modifying columns) without rewriting the entire dataset**
- Automatically handles **backward compatibility**
- **Minimizes downtime** and **storage costs**

### 4. **Partition Evolution**
- Allows changing the **partitioning strategy** without requiring data migration
- Provides flexibility to **optimize query performance over time**

### 5. **Hidden Partitioning**
- Partitions are **automatically managed by Iceberg**
- Query engines automatically apply **partition pruning**
- Queries do **not require knowledge of the underlying partition structure**

### 6. **Performance Optimization**
- Metadata is **stored efficiently**, reducing overhead from **file listing operations**
- Supports **file-level statistics for query optimization**
- Integrates well with Spark, Presto, Trino, and other query engines

## ğŸ—ï¸ Architecture and Configuration

### General Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gold Layer                           â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Apache Iceberg Tables                    â”‚   â”‚
â”‚  â”‚  - sk_registry                                   â”‚   â”‚
â”‚  â”‚  - bridge_user_plan                              â”‚   â”‚
â”‚  â”‚  - dim_category                                  |   |
|  |  - dim_network                                   |   |
|  |  - dim_platform                                  |   |               
â”‚  â”‚  - dim_subscription                              |   |
|  |  - dim_user                                      |   |
|  |  - fact_customer_search                          |   |
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                              â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      AWS Glue Catalog (Metadata Catalog)         â”‚   â”‚
â”‚  â”‚  - Manage table metadata                         â”‚   â”‚
â”‚  â”‚  - Schema definitions                            â”‚   â”‚
â”‚  â”‚  - Table properties                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                              â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      S3 Warehouse (Data + Metadata)              â”‚   â”‚
â”‚  â”‚  - Data files (Parquet)                          â”‚   â”‚
â”‚  â”‚  - Metadata files (JSON)                         â”‚   â”‚
â”‚  â”‚  - Manifest files                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
  

![AWS_Glue_Data_Catalog](/image/AWS_Glue_Data_Catalog.png)
<p align="center">
  <em> AWS Glue Data Catalog</em>
</p>


![iceberg_tbl_detail](/image/iceberg_tbl_detail.png)
<p align="center">
  <em> Apache Iceberg table details in AWS Glue Data Catalog</em>
</p>
### Cáº¥u hÃ¬nh Spark Session

Iceberg Ä‘Æ°á»£c cáº¥u hÃ¬nh trong hÃ m `create_gold_spark_session()` vá»›i cÃ¡c thÃ´ng sá»‘ sau:

```python
# Iceberg Extensions
spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# Catalog Configuration
spark.sql.catalog.iceberg = org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.catalog-impl = org.apache.iceberg.aws.glue.GlueCatalog
spark.sql.catalog.iceberg.warehouse = s3a://data-pipeline-e2e-datalake-98c619f9/iceberg-warehouse
spark.sql.catalog.iceberg.io-impl = org.apache.iceberg.aws.s3.S3FileIO
```

### ThÃ nh pháº§n chÃ­nh

1. **AWS Glue Catalog**: LÆ°u trá»¯ metadata vá» tables, schemas, vÃ  partitions
   - TÃ­ch há»£p vá»›i AWS Glue Data Catalog
   - CÃ³ thá»ƒ query tá»« Athena, Redshift Spectrum, vÃ  cÃ¡c tools khÃ¡c

2. **S3 Warehouse**: LÆ°u trá»¯ dá»¯ liá»‡u vÃ  metadata files
   - **Data files**: Dá»¯ liá»‡u thá»±c táº¿ dÆ°á»›i dáº¡ng Parquet
   - **Metadata files**: ThÃ´ng tin vá» snapshots, schemas, vÃ  partition specs
   - **Manifest files**: Danh sÃ¡ch cÃ¡c data files trong má»—i snapshot

3. **JAR Dependencies**:
   - `iceberg-spark-runtime-3.5_2.12-1.5.2.jar`: Spark runtime cho Iceberg
   - `iceberg-aws-bundle-1.5.2.jar`: AWS integration (Glue Catalog, S3)

## ğŸ’» CÃ¡ch sá»­ dá»¥ng trong Dá»± Ã¡n

### 1. Táº¡o Namespace vÃ  Table

```python
# Táº¡o namespace
spark.sql("CREATE NAMESPACE IF NOT EXISTS iceberg.gold")

# Táº¡o table vá»›i schema Ä‘á»‹nh nghÄ©a sáºµn
spark.sql("""
    CREATE TABLE IF NOT EXISTS iceberg.gold.dim_category(
        category_key   int,
        category_name   string,
        category_slug    string
    )
    USING iceberg;
""")
```

### 2. Append Data (Insert má»›i)

```python
# Append data vÃ o table
insert_df.writeTo("iceberg.gold.dim_category").append()
```

### 3. Merge Data (Upsert)

```python
# Sá»­ dá»¥ng MERGE INTO cho upsert operations
spark.sql("""
    MERGE INTO iceberg.gold.sk_registry t
    USING stg_registry s
    ON t.entity_name = s.entity_name
    WHEN MATCHED THEN
      UPDATE SET
        current_max = s.current_max,
        updated_at  = s.updated_at
    WHEN NOT MATCHED THEN
      INSERT (entity_name, current_max, updated_at)
      VALUES (s.entity_name, s.current_max, s.updated_at)
""")
```

### 4. Query Data

```python
# Query tá»« Iceberg table
df = spark.sql("SELECT * FROM iceberg.gold.dim_category")

# Hoáº·c sá»­ dá»¥ng DataFrame API
df = spark.read.format("iceberg").load("iceberg.gold.dim_category")
```

### 5. Time Travel Queries

```python
# Query dá»¯ liá»‡u táº¡i má»™t snapshot cá»¥ thá»ƒ
df = spark.read \
    .option("as-of-timestamp", "2024-01-01 00:00:00") \
    .format("iceberg") \
    .load("iceberg.gold.dim_category")

# Hoáº·c query táº¡i má»™t snapshot ID
df = spark.read \
    .option("snapshot-id", 1234567890) \
    .format("iceberg") \
    .load("iceberg.gold.dim_category")
```

## ğŸ“ VÃ­ dá»¥ thá»±c táº¿ trong Dá»± Ã¡n

### File: `_030302_dim_category_append.py`

File nÃ y minh há»a cÃ¡ch sá»­ dá»¥ng Iceberg Ä‘á»ƒ:
1. Táº¡o table náº¿u chÆ°a tá»“n táº¡i
2. Äá»c dá»¯ liá»‡u tá»« Silver layer
3. Transform vÃ  chuáº©n bá»‹ dá»¯ liá»‡u
4. So sÃ¡nh vá»›i dá»¯ liá»‡u hiá»‡n cÃ³ Ä‘á»ƒ chá»‰ insert records má»›i
5. Append data vÃ o Iceberg table

```python
# Táº¡o table
spark.sql("""CREATE TABLE IF NOT EXISTS iceberg.gold.dim_category(...) USING iceberg;""")

# Äá»c dá»¯ liá»‡u cÅ©
tg_df_old = spark.sql("SELECT * FROM iceberg.gold.dim_category")

# So sÃ¡nh vÃ  chá»‰ láº¥y dá»¯ liá»‡u má»›i
insert_df = tg_df.subtract(tg_df_old)

# Append dá»¯ liá»‡u má»›i
if insert_df.count() > 0:
    insert_df.writeTo("iceberg.gold.dim_category").append()
```

### File: `surrogate_key_registry.py`

Sá»­ dá»¥ng Iceberg table Ä‘á»ƒ quáº£n lÃ½ surrogate keys:
- Table `iceberg.gold.sk_registry` lÆ°u trá»¯ max key hiá»‡n táº¡i cho má»—i entity
- Sá»­ dá»¥ng `MERGE INTO` Ä‘á»ƒ update registry má»™t cÃ¡ch atomic
- Äáº£m báº£o khÃ´ng cÃ³ duplicate keys khi cháº¡y parallel jobs

## ğŸ” CÃ¡c tÃ­nh nÄƒng nÃ¢ng cao

### 1. Schema Evolution

```python
# ThÃªm cá»™t má»›i
spark.sql("ALTER TABLE iceberg.gold.dim_category ADD COLUMN description string")

# Äá»•i tÃªn cá»™t
spark.sql("ALTER TABLE iceberg.gold.dim_category RENAME COLUMN category_name TO name")

# XÃ³a cá»™t
spark.sql("ALTER TABLE iceberg.gold.dim_category DROP COLUMN old_column")
```

### 2. Partitioning

```python
# Táº¡o table vá»›i partition
spark.sql("""
    CREATE TABLE iceberg.gold.fact_sales(
        sale_id bigint,
        sale_date date,
        amount decimal(10,2)
    )
    USING iceberg
    PARTITIONED BY (days(sale_date))
""")
```

### 3. Table Properties

```python
# Set table properties khi táº¡o table
spark.sql("""
    CREATE TABLE iceberg.gold.dim_category(...)
    USING iceberg
    TBLPROPERTIES (
        'write.target-file-size-bytes'='536870912',
        'write.parquet.compression-codec'='zstd'
    )
""")
```

### 4. Expire Snapshots

```python
# XÃ³a cÃ¡c snapshots cÅ© Ä‘á»ƒ giáº£i phÃ³ng storage
spark.sql("CALL iceberg.system.expire_snapshots('iceberg.gold.dim_category', TIMESTAMP '2024-01-01 00:00:00')")
```

## âœ… Lá»£i Ã­ch cá»¥ thá»ƒ trong Dá»± Ã¡n

### 1. **Data Quality & Consistency**
- ACID transactions Ä‘áº£m báº£o dá»¯ liá»‡u luÃ´n consistent
- Há»— trá»£ upsert operations vá»›i `MERGE INTO`
- TrÃ¡nh Ä‘Æ°á»£c partial writes vÃ  data corruption

### 2. **Operational Efficiency**
- KhÃ´ng cáº§n quáº£n lÃ½ partition paths thá»§ cÃ´ng
- Metadata Ä‘Æ°á»£c quáº£n lÃ½ tá»± Ä‘á»™ng
- Dá»… dÃ ng thÃªm/xÃ³a/sá»­a schema mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n dá»¯ liá»‡u hiá»‡n cÃ³

### 3. **Cost Optimization**
- Chá»‰ cáº§n Ä‘á»c cÃ¡c files liÃªn quan nhá» metadata optimization
- Há»— trá»£ compaction Ä‘á»ƒ tá»‘i Æ°u storage
- CÃ³ thá»ƒ expire snapshots cÅ© Ä‘á»ƒ giáº£m storage costs

### 4. **Integration vá»›i AWS Services**
- TÃ­ch há»£p vá»›i AWS Glue Catalog â†’ cÃ³ thá»ƒ query tá»« Athena, Redshift Spectrum
- Sá»­ dá»¥ng S3 lÃ m storage layer â†’ cost-effective vÃ  scalable
- TÆ°Æ¡ng thÃ­ch vá»›i cÃ¡c AWS analytics services

### 5. **Developer Experience**
- SQL-like interface, dá»… sá»­ dá»¥ng
- Há»— trá»£ tá»‘t vá»›i Spark DataFrame API
- Time travel giÃºp debug vÃ  audit dá»… dÃ ng hÆ¡n

## ğŸš€ Best Practices

### 1. **Table Naming Convention**
- Sá»­ dá»¥ng namespace Ä‘á»ƒ tá»• chá»©c: `iceberg.gold.*`, `iceberg.silver.*`
- Äáº·t tÃªn table rÃµ rÃ ng, theo convention cá»§a dá»± Ã¡n

### 2. **Write Operations**
- Sá»­ dá»¥ng `append()` cho insert-only workloads
- Sá»­ dá»¥ng `MERGE INTO` cho upsert operations
- Batch writes Ä‘á»ƒ tá»‘i Æ°u performance

### 3. **Partitioning Strategy**
- Chá»n partition columns dá»±a trÃªn query patterns
- TrÃ¡nh over-partitioning (quÃ¡ nhiá»u small files)
- Sá»­ dá»¥ng hidden partitioning khi cÃ³ thá»ƒ

### 4. **Maintenance**
- Äá»‹nh ká»³ expire snapshots cÅ©
- Cháº¡y compaction Ä‘á»ƒ merge small files
- Monitor table size vÃ  file count

### 5. **Error Handling**
- LuÃ´n check sá»‘ lÆ°á»£ng records trÆ°á»›c khi write
- Sá»­ dá»¥ng try-catch cho cÃ¡c operations
- Log cÃ¡c operations quan trá»ng

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Apache Iceberg Official Documentation](https://iceberg.apache.org/)
- [Iceberg Spark Integration](https://iceberg.apache.org/docs/latest/spark-configuration/)
- [AWS Glue Catalog Integration](https://iceberg.apache.org/docs/latest/aws/)
- [Iceberg Specification](https://iceberg.apache.org/spec/)

## ğŸ”— LiÃªn quan Ä‘áº¿n cÃ¡c thÃ nh pháº§n khÃ¡c

- **Silver Layer**: Dá»¯ liá»‡u tá»« Silver layer (Parquet trÃªn S3) Ä‘Æ°á»£c Ä‘á»c vÃ  transform trÆ°á»›c khi load vÃ o Iceberg tables
- **Redshift**: Dá»¯ liá»‡u tá»« Iceberg tables cÃ³ thá»ƒ Ä‘Æ°á»£c sync sang Redshift Ä‘á»ƒ phá»¥c vá»¥ BI tools
- **AWS Glue**: Sá»­ dá»¥ng Glue Catalog Ä‘á»ƒ quáº£n lÃ½ metadata, cÃ³ thá»ƒ query tá»« Glue/Athena
- **S3**: Warehouse path: `s3a://data-pipeline-e2e-datalake-98c619f9/iceberg-warehouse`

---

**LÆ°u Ã½**: TÃ i liá»‡u nÃ y Ä‘Æ°á»£c cáº­p nháº­t dá»±a trÃªn implementation hiá»‡n táº¡i cá»§a dá»± Ã¡n. Khi cÃ³ thay Ä‘á»•i vá» cáº¥u hÃ¬nh hoáº·c cÃ¡ch sá»­ dá»¥ng, vui lÃ²ng cáº­p nháº­t tÃ i liá»‡u nÃ y.

